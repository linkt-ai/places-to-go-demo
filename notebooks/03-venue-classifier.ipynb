{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# BERT Venue Classfier Training\n",
    "\n",
    "Now that we have a labeled venue dataset, we need a way to create classification scores for each persona for each venue. We can use an 8 head classification model for this task. By taking BERT, and feeding the business name, categories, feature list and one sentence description (or some subset of these elements) into the model as input, we can use the persona labels provided by GPT to fine-tune a BERT checkpoint on providing relationship scores between a venue and our set of personas.\n",
    "\n",
    "1. **Dataset Creation**\n",
    "\n",
    "We will want to start by creating a labeled dataset that can be fed directly to BERT for a fine-tuning job. This will allow us to setup a function for transforming a row into an input prompt, which we will be able to modify to test different results of the BERT encoder model.\n",
    "\n",
    "2. **Fine-Tuning**\n",
    "\n",
    "We will fine-tune the model using the labelled dataset. This should utilize hugginface and the `AutoModelForSequenceClassfication` class, which will wrap our BERT checkpoint and tokenizer.\n",
    "\n",
    "3. **Evaluation**\n",
    "\n",
    "After the evaluation is complete, we will assess the model's perfromance on our test dataset. This will allow us to see how well the model distributes the scores for the 8 labels for each venue. We can modify the input string if necessary based on these results."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "True"
      ]
     },
     "execution_count": 1,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import json\n",
    "\n",
    "import pandas as pd\n",
    "from dotenv import load_dotenv\n",
    "\n",
    "load_dotenv()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Dataset Creation\n",
    "\n",
    "For starters, we will setup a pipeline to take our Yelp location data and create rows that can be used to fine-tune our classifier model."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "with open(\"../data/venues/yelp.json\", \"r\") as f:\n",
    "    location_data = json.load(f)\n",
    "\n",
    "personas = [\"socialButterfly\", \"culinaryExplorer\", \"beautyFashionAficionado\", \"familyOrientedIndividual\", \"artCultureEnthusiast\", \"wellnessSelfCareAdvocate\", \"adventurerExplorer\", \"ecoConsciousConsumer\"]\n",
    "\n",
    "dataset = []\n",
    "for loc in location_data:\n",
    "    labels = {persona: 1 if persona in loc['personas'] else 0 for persona in personas}\n",
    "    data = {\n",
    "        \"id\": loc[\"id\"],\n",
    "        \"biz_name\": loc[\"name\"],\n",
    "        \"categories\": ', '.join([cat['title'] for cat in loc[\"categories\"]]),\n",
    "        \"biz_features\": loc[\"biz_features\"],\n",
    "        'summary': loc[\"business_summary\"],\n",
    "    }\n",
    "    row = {**data, **labels}\n",
    "    dataset.append(row)\n",
    "\n",
    "df = pd.DataFrame(dataset)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "def format_input(row):\n",
    "    return (\n",
    "        f\"Name: {row.biz_name}\\n\"\n",
    "        f\"Categories: {row.categories}\\n\"\n",
    "        f\"Biz Features: {row.biz_features}\\n\"\n",
    "        f\"Summary: {row.summary}\\n\"\n",
    "    )\n",
    "\n",
    "df['input'] = df.apply(format_input, axis=1)\n",
    "\n",
    "# inputs = tokenizer(df['input'].tolist(), return_tensors='pt', padding=True, truncation=True, max_length=512)\n",
    "# labels = torch.tensor(df[personas].values, dtype=torch.float)\n",
    "\n",
    "# dataset = TensorDataset(inputs['input_ids'], inputs['attention_mask'], labels)\n",
    "# train_size = int(0.9 * len(dataset))\n",
    "# val_size = len(dataset) - train_size\n",
    "\n",
    "# train_dataset, val_dataset = random_split(dataset, [train_size, val_size])\n",
    "\n",
    "# train_dataloader = DataLoader(train_dataset, batch_size=16, shuffle=True)\n",
    "# val_dataloader = DataLoader(val_dataset, batch_size=16)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Fine-Tuning the Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/jackmoffatt/Development/repositories/places-to-go-demo/.venv/lib/python3.11/site-packages/tqdm/auto.py:21: TqdmWarning: IProgress not found. Please update jupyter and ipywidgets. See https://ipywidgets.readthedocs.io/en/stable/user_install.html\n",
      "  from .autonotebook import tqdm as notebook_tqdm\n",
      "Some weights of DistilBertForSequenceClassification were not initialized from the model checkpoint at distilbert-base-uncased and are newly initialized: ['pre_classifier.weight', 'classifier.bias', 'pre_classifier.bias', 'classifier.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n"
     ]
    }
   ],
   "source": [
    "from transformers import AutoModelForSequenceClassification, AutoTokenizer\n",
    "\n",
    "bert_chkpt = \"distilbert-base-uncased\"\n",
    "\n",
    "model = AutoModelForSequenceClassification.from_pretrained(bert_chkpt, num_labels=len(personas), problem_type=\"multi_label_classification\")\n",
    "tokenizer = AutoTokenizer.from_pretrained(bert_chkpt)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "import numpy as np\n",
    "from datasets import Dataset, DatasetDict\n",
    "\n",
    "inputs = tokenizer(df.input.tolist(), return_tensors='pt', padding=True, truncation=True, max_length=512)\n",
    "labels = torch.tensor(df[personas].values, dtype=torch.float)\n",
    "\n",
    "indicies = np.arange(len(labels))\n",
    "\n",
    "np.random.seed(100)\n",
    "np.random.shuffle(indicies)\n",
    "\n",
    "train_indicies = indicies[:800]\n",
    "val_indicies = indicies[800:1000]\n",
    "test_indicies = indicies[1000:]\n",
    "\n",
    "train_dataset = Dataset.from_dict({'input_ids': inputs['input_ids'][train_indicies], 'attention_mask': inputs['attention_mask'][train_indicies], 'labels': labels[train_indicies]})\n",
    "val_dataset = Dataset.from_dict({'input_ids': inputs['input_ids'][val_indicies], 'attention_mask': inputs['attention_mask'][val_indicies], 'labels': labels[val_indicies]})\n",
    "test_dataset = Dataset.from_dict({'input_ids': inputs['input_ids'][test_indicies], 'attention_mask': inputs['attention_mask'][test_indicies], 'labels': labels[test_indicies]})\n",
    "\n",
    "dataset_dict = DatasetDict({\n",
    "    'train': train_dataset,\n",
    "    'val': val_dataset,\n",
    "    'test': test_dataset\n",
    "})\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  0%|          | 0/150 [14:38<?, ?it/s]\n"
     ]
    }
   ],
   "source": [
    "from transformers import Trainer, TrainingArguments\n",
    "\n",
    "training_args = TrainingArguments(\n",
    "    output_dir='./results',          # output directory\n",
    "    num_train_epochs=3,              # total number of training epochs\n",
    "    per_device_train_batch_size=16,  # batch size per device during training\n",
    "    per_device_eval_batch_size=64,   # batch size for evaluation\n",
    "    warmup_steps=500,                # number of warmup steps for learning rate scheduler\n",
    "    weight_decay=0.01,               # strength of weight decay\n",
    "    logging_dir='./logs',            # directory for storing logs\n",
    ")\n",
    "\n",
    "trainer = Trainer(\n",
    "    model=model,                            # the instantiated ðŸ¤— Transformers model to be trained\n",
    "    args=training_args,                     # training arguments, defined above\n",
    "    train_dataset=dataset_dict['train'],    # training dataset\n",
    "    eval_dataset=dataset_dict['val']        # evaluation dataset\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 150/150 [01:01<00:00,  2.45it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'train_runtime': 61.2616, 'train_samples_per_second': 39.176, 'train_steps_per_second': 2.449, 'train_loss': 0.5250987752278646, 'epoch': 3.0}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    }
   ],
   "source": [
    "result = trainer.train()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 60,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 7/7 [00:02<00:00,  2.86it/s]\n"
     ]
    }
   ],
   "source": [
    "import torch\n",
    "import numpy as np\n",
    "\n",
    "label_map = {i: label for i, label in enumerate(personas)}\n",
    "predictions = trainer.predict(dataset_dict['test'])\n",
    "predictions_tensor = torch.tensor(predictions.predictions)\n",
    "\n",
    "predictions = torch.nn.functional.softmax(predictions_tensor, dim=-1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 61,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>socialButterfly</th>\n",
       "      <th>culinaryExplorer</th>\n",
       "      <th>beautyFashionAficionado</th>\n",
       "      <th>familyOrientedIndividual</th>\n",
       "      <th>artCultureEnthusiast</th>\n",
       "      <th>wellnessSelfCareAdvocate</th>\n",
       "      <th>adventurerExplorer</th>\n",
       "      <th>ecoConsciousConsumer</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>count</th>\n",
       "      <td>425.000000</td>\n",
       "      <td>425.000000</td>\n",
       "      <td>425.000000</td>\n",
       "      <td>425.000000</td>\n",
       "      <td>425.000000</td>\n",
       "      <td>425.000000</td>\n",
       "      <td>425.000000</td>\n",
       "      <td>425.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>mean</th>\n",
       "      <td>0.146046</td>\n",
       "      <td>0.140709</td>\n",
       "      <td>0.038303</td>\n",
       "      <td>0.119202</td>\n",
       "      <td>0.171325</td>\n",
       "      <td>0.054139</td>\n",
       "      <td>0.294034</td>\n",
       "      <td>0.036241</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>std</th>\n",
       "      <td>0.110230</td>\n",
       "      <td>0.163272</td>\n",
       "      <td>0.009131</td>\n",
       "      <td>0.037351</td>\n",
       "      <td>0.140378</td>\n",
       "      <td>0.011574</td>\n",
       "      <td>0.236626</td>\n",
       "      <td>0.005121</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>min</th>\n",
       "      <td>0.034029</td>\n",
       "      <td>0.022724</td>\n",
       "      <td>0.023940</td>\n",
       "      <td>0.055401</td>\n",
       "      <td>0.043957</td>\n",
       "      <td>0.033863</td>\n",
       "      <td>0.036282</td>\n",
       "      <td>0.027742</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>25%</th>\n",
       "      <td>0.054828</td>\n",
       "      <td>0.032655</td>\n",
       "      <td>0.027731</td>\n",
       "      <td>0.101143</td>\n",
       "      <td>0.059879</td>\n",
       "      <td>0.046889</td>\n",
       "      <td>0.088899</td>\n",
       "      <td>0.032732</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>50%</th>\n",
       "      <td>0.095441</td>\n",
       "      <td>0.053213</td>\n",
       "      <td>0.042869</td>\n",
       "      <td>0.128139</td>\n",
       "      <td>0.097326</td>\n",
       "      <td>0.056167</td>\n",
       "      <td>0.171892</td>\n",
       "      <td>0.036082</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>75%</th>\n",
       "      <td>0.253147</td>\n",
       "      <td>0.179457</td>\n",
       "      <td>0.045280</td>\n",
       "      <td>0.147980</td>\n",
       "      <td>0.293614</td>\n",
       "      <td>0.063199</td>\n",
       "      <td>0.556664</td>\n",
       "      <td>0.040064</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>max</th>\n",
       "      <td>0.424459</td>\n",
       "      <td>0.501917</td>\n",
       "      <td>0.059434</td>\n",
       "      <td>0.189813</td>\n",
       "      <td>0.456688</td>\n",
       "      <td>0.078829</td>\n",
       "      <td>0.670703</td>\n",
       "      <td>0.048961</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "       socialButterfly  culinaryExplorer  beautyFashionAficionado  \\\n",
       "count       425.000000        425.000000               425.000000   \n",
       "mean          0.146046          0.140709                 0.038303   \n",
       "std           0.110230          0.163272                 0.009131   \n",
       "min           0.034029          0.022724                 0.023940   \n",
       "25%           0.054828          0.032655                 0.027731   \n",
       "50%           0.095441          0.053213                 0.042869   \n",
       "75%           0.253147          0.179457                 0.045280   \n",
       "max           0.424459          0.501917                 0.059434   \n",
       "\n",
       "       familyOrientedIndividual  artCultureEnthusiast  \\\n",
       "count                425.000000            425.000000   \n",
       "mean                   0.119202              0.171325   \n",
       "std                    0.037351              0.140378   \n",
       "min                    0.055401              0.043957   \n",
       "25%                    0.101143              0.059879   \n",
       "50%                    0.128139              0.097326   \n",
       "75%                    0.147980              0.293614   \n",
       "max                    0.189813              0.456688   \n",
       "\n",
       "       wellnessSelfCareAdvocate  adventurerExplorer  ecoConsciousConsumer  \n",
       "count                425.000000          425.000000            425.000000  \n",
       "mean                   0.054139            0.294034              0.036241  \n",
       "std                    0.011574            0.236626              0.005121  \n",
       "min                    0.033863            0.036282              0.027742  \n",
       "25%                    0.046889            0.088899              0.032732  \n",
       "50%                    0.056167            0.171892              0.036082  \n",
       "75%                    0.063199            0.556664              0.040064  \n",
       "max                    0.078829            0.670703              0.048961  "
      ]
     },
     "execution_count": 61,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "labels_df = pd.DataFrame(predictions, columns=personas)\n",
    "labels_df.describe()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "metadata": {},
   "outputs": [],
   "source": [
    "trainer.save_model(\"../models/bert-yelp\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": ".venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
