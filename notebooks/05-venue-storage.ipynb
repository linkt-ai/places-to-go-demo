{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Storage of Venue Data\n",
    "Now that we have extracted the keywords from our venue list, it is time to store the Venue's and keywords in a graph database. Additionally, we will need to store each venue in our document vectorstroe as well. To do this we will need to parse the extracted keyword-venue JSON objects to create Cypher Statements for writing the entities and relationships to our Neo4J database and then use the vectorstore docs to upsert our venue document vectors to Pinecone.\n",
    "\n",
    "This notebook will walk us through a few principle steps:\n",
    "1. **Creating Cyphers from the extracted JSON data**\n",
    "2. **Using Cyphers to write to Neo4J**\n",
    "3. **Writing venue documents to pinecone**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "True"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import os\n",
    "from dotenv import load_dotenv\n",
    "\n",
    "load_dotenv()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "import json\n",
    "import re\n",
    "\n",
    "with open(\"../data/venues/cypher_data.json\", 'r') as location_data:\n",
    "    entity_data = json.load(location_data)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Creating Cypher Statements from the extracted Venue data\n",
    "\n",
    "Now that we have our `cypher_entities`, we can use them to format our cypher statments, for writing a query to the graph database."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "from typing import Dict, List, Union\n",
    "\n",
    "def make_safe(val: Union[str| float]) -> Union[str | float]:\n",
    "    \"\"\"Make a string with ' characters safe for Cypher\"\"\"\n",
    "    if type(val) == str:\n",
    "        return val.replace(\"'\", \"\\\\'\")\n",
    "    return val\n",
    "    \n",
    "def generate_cypher(venue: Dict[str, Union[str, float, List[str]]]) -> str:\n",
    "    e_statements = []\n",
    "    r_statements = []\n",
    "\n",
    "    venue_properties = \", \".join([f\"{key}: '{make_safe(value)}'\" for key, value in venue['venue'].items()]) if 'venue' in venue else \"\"\n",
    "    venue_cypher = f\"MERGE (v:Venue {{ {venue_properties} }})\"\n",
    "    e_statements.append(venue_cypher)\n",
    "\n",
    "    for i, items in enumerate(venue['personas'].items()):\n",
    "        persona, weight = items\n",
    "        persona_cypher = f\"MERGE (p{i+1}:Persona {{ value: '{make_safe(persona)}' }})\"\n",
    "        e_statements.append(persona_cypher)\n",
    "        r_statements.append(f\"MERGE (v)-[r{i+1}:PERSONA_RELEVANCE]->(p{i+1}) SET r{i+1}.weight = {weight}\") \n",
    "    \n",
    "    return e_statements, r_statements"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "cypher_statements = []\n",
    "\n",
    "# Conver the cypher entity data into cypher statements\n",
    "for venue in entity_data:\n",
    "    e_statements, r_statements = generate_cypher(venue)\n",
    "    cypher_statemnt = \"\\n\".join(e_statements + r_statements)\n",
    "    cypher_statements.append(cypher_statemnt)\n",
    "\n",
    "assert len(cypher_statements) == len(entity_data)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Using Cypher Statements to Write to Neo4J\n",
    "\n",
    "With our Cypher statements in hand, we will update the Neo4J database to store our Venue and Keyword entites. The usage of the 'MERGE' keyword will prevent nodes from being duplicated."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "from neo4j import GraphDatabase\n",
    "\n",
    "DB_USER = os.getenv(\"NEO4J_DATABASE_USERNAME\")\n",
    "DB_URL = os.getenv(\"NEO4J_DATABASE_URL\")\n",
    "DB_PASSWORD = os.getenv(\"NEO4J_DATABASE_PASSWORD\")\n",
    "\n",
    "def get_driver():\n",
    "    return GraphDatabase.driver(DB_URL, auth=(DB_USER, DB_PASSWORD))\n",
    "\n",
    "driver = get_driver()\n",
    "\n",
    "with driver.session() as session:\n",
    "    for statement in cypher_statements:\n",
    "        session.run(statement)\n",
    "\n",
    "driver.close()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Writing the Venue Documents to Pinecone\n",
    "\n",
    "Next, we will load our vectorstore documents, and use them to write all of our documents to pinecone. Again, the use of the `upsert` method, will prevent records with the same ID from being duplicated."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pinecone\n",
    "\n",
    "PINECONE_API_KEY = os.getenv(\"PINECONE_API_KEY\")\n",
    "PINECONE_ENVIRONMENT = os.getenv(\"PINECONE_ENVIRONMENT\")\n",
    "PINECONE_INDEX = os.getenv(\"PINECONE_INDEX\")\n",
    "\n",
    "pinecone.init(api_key=PINECONE_API_KEY, environment=PINECONE_ENVIRONMENT)\n",
    "index = pinecone.Index(PINECONE_INDEX)\n",
    "\n",
    "\n",
    "with open(\"../data/venues/vectorstore_docs.json\", \"r\") as f:\n",
    "    vectorstore_docs = json.load(f)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 6/6 [00:10<00:00,  1.69s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Upserted 1425 vectors\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    }
   ],
   "source": [
    "from tqdm import tqdm\n",
    "\n",
    "def store_docs(docs):\n",
    "    try:\n",
    "        BATCH_SIZE = 250\n",
    "        count = 0\n",
    "        for start in tqdm(range(0, len(docs), BATCH_SIZE)):\n",
    "            # Select the batch\n",
    "            batch = docs[start:start+BATCH_SIZE]\n",
    "            upsert_response = index.upsert(vectors=batch, namespace='venues')\n",
    "            \n",
    "            # Log the results\n",
    "            count += upsert_response['upserted_count']\n",
    "\n",
    "        print(f\"Upserted {count} vectors\")\n",
    "        return count\n",
    "    except Exception as e:\n",
    "        print(e)\n",
    "        return 0\n",
    "\n",
    "upserted_count = store_docs(vectorstore_docs)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Testing the Results\n",
    "\n",
    "Finally, we want to see how well our results correspond to a user's query. This will help us determine what threshold to set when we are receiving results from our pinecone query."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [],
   "source": [
    "from typing import Tuple\n",
    "from openai import OpenAI\n",
    "\n",
    "import urllib.parse\n",
    "\n",
    "openai_client = OpenAI()\n",
    "\n",
    "def get_relevant_businesses(city: str, category: str, query: str) -> List[Tuple[str, str]]:\n",
    "    \"\"\"Get the relevant businesses from the databases.\"\"\"\n",
    "    # First, we need to embed the query\n",
    "    response = openai_client.embeddings.create(input=query, model=\"text-embedding-ada-002\")\n",
    "    embeddings = response.data[0].embedding\n",
    "\n",
    "\n",
    "    # First we need to query pinecone, to get the IDs of the relevant businesses\n",
    "    query_response = index.query(vector=embeddings, top_k=100, namespace='venues', filter={'city': {'$eq': city}, 'category': {'$eq': category}})\n",
    "    ids = [result['id'] for result in query_response['matches']]\n",
    "    \n",
    "    # Now we need to query Neo4J, to get the details of the businesses\n",
    "    driver = get_driver()\n",
    "    with driver.session() as session:\n",
    "        results = session.run(f\"MATCH (v:Venue) WHERE v.id IN {ids} RETURN v\")\n",
    "        \n",
    "        data = []\n",
    "        for record in results:\n",
    "            venue = record['v']\n",
    "            data.append((\n",
    "                venue['name'], \n",
    "                urllib.parse.unquote(venue['url'])\n",
    "            ))\n",
    "\n",
    "    driver.close()\n",
    "\n",
    "    return data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": ".venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
